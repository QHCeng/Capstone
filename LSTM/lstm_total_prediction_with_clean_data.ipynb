{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a376e3cd-c2c6-4b06-b9cd-cf35cd924fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7120a87-5a25-45b7-a9c4-89ca50d6e671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suzreal\\AppData\\Local\\Temp\\ipykernel_31728\\2815772411.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['is_holiday'] = df['is_holiday'].replace({False: 0, True: 1})\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year_month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_expense",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "txn_count_prev",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_expense_prev",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user_gender",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_current_age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_yearly_income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user_per_capita_income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user_credit_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_total_debt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user_birth_month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "card_num_cards_issued",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year_to_retirement",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "debt_to_yearly_income_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "income_per_card",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "multi_card_user",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "income_utilization_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "credit_utilization_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oldest_card_age_years",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weekend_spend_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "correlation_with_trend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "risk_of_default_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "risk_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "percentage_prev_monthly_expense_as_yearly",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "percentage_prev_monthly_expense_as_capita",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_1_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_2_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_3_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_5_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_6_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_7_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_9_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_11_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_12_spending",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1y_holiday_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_holiday",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "05969e7f-612f-4b00-aad1-0d764ba2fc99",
       "rows": [
        [
         "0",
         "0",
         "2015-01-01",
         "5249.9",
         "128.0",
         "6185.2",
         "53.0",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "10.4",
         "21.2",
         "7091.15",
         "3859.24",
         "6766.18",
         "4266.63",
         "6777.58",
         "6604.68",
         "5055.62",
         "5109.56",
         "6169.59",
         "-1252.7200000000005",
         "1"
        ],
        [
         "1",
         "0",
         "2015-02-01",
         "4229.7",
         "99.0",
         "5249.9",
         "49.2",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "8.8",
         "18.0",
         "4916.87",
         "7091.15",
         "3859.24",
         "5642.49",
         "4266.63",
         "6777.58",
         "7068.7",
         "4600.44",
         "5109.56",
         "-739.9000000000005",
         "1"
        ],
        [
         "2",
         "0",
         "2015-03-01",
         "4595.4",
         "86.0",
         "4229.7",
         "45.5",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "7.1",
         "14.5",
         "4369.66",
         "4916.87",
         "7091.15",
         "6766.18",
         "5642.49",
         "4266.63",
         "6604.68",
         "5055.62",
         "4600.44",
         "0.0",
         "0"
        ],
        [
         "3",
         "0",
         "2015-04-01",
         "4586.5",
         "101.0",
         "4595.4",
         "47.8",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "7.7",
         "15.7",
         "5495.42",
         "4369.66",
         "4916.87",
         "3859.24",
         "6766.18",
         "5642.49",
         "6777.58",
         "7068.7",
         "5055.62",
         "0.0",
         "0"
        ],
        [
         "4",
         "0",
         "2015-05-01",
         "5864.1",
         "96.0",
         "4586.5",
         "50.6",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "7.7",
         "15.7",
         "4938.54",
         "5495.42",
         "4369.66",
         "7091.15",
         "3859.24",
         "6766.18",
         "4266.63",
         "6604.68",
         "7068.7",
         "-1420.5699999999997",
         "1"
        ],
        [
         "5",
         "0",
         "2015-06-01",
         "6104.9",
         "116.0",
         "5864.1",
         "57.6",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "9.8",
         "20.1",
         "5648.13",
         "4938.54",
         "5495.42",
         "4916.87",
         "7091.15",
         "3859.24",
         "5642.49",
         "6777.58",
         "6604.68",
         "0.0",
         "0"
        ],
        [
         "6",
         "0",
         "2015-07-01",
         "5504.0",
         "106.0",
         "6104.9",
         "59.8",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "10.2",
         "20.9",
         "5886.93",
         "5648.13",
         "4938.54",
         "4369.66",
         "4916.87",
         "7091.15",
         "6766.18",
         "4266.63",
         "6777.58",
         "-1133.5299999999995",
         "1"
        ],
        [
         "7",
         "0",
         "2015-08-01",
         "5029.5",
         "92.0",
         "5504.1",
         "48.8",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "9.2",
         "18.8",
         "5644.05",
         "5886.93",
         "5648.13",
         "5495.42",
         "4369.66",
         "4916.87",
         "3859.24",
         "5642.49",
         "4266.63",
         "0.0",
         "0"
        ],
        [
         "8",
         "0",
         "2015-09-01",
         "5329.9",
         "103.0",
         "5029.5",
         "56.7",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "8.4",
         "17.2",
         "5029.51",
         "5644.05",
         "5886.93",
         "4938.54",
         "5495.42",
         "4369.66",
         "7091.15",
         "6766.18",
         "5642.49",
         "67.42000000000007",
         "1"
        ],
        [
         "9",
         "0",
         "2015-10-01",
         "6071.2",
         "94.0",
         "5329.9",
         "58.9",
         "0",
         "33",
         "59613.0",
         "29237.0",
         "763",
         "36199.0",
         "3",
         "1",
         "43.6",
         "-70.3",
         "36",
         "0.6",
         "59613.0",
         "0",
         "1.1",
         "0.0",
         "18",
         "0.3",
         "0.2",
         "0.2",
         "0",
         "2",
         "8.9",
         "18.2",
         "5709.91",
         "5029.51",
         "5644.05",
         "5648.13",
         "4938.54",
         "5495.42",
         "4916.87",
         "3859.24",
         "6766.18",
         "-495.0200000000005",
         "1"
        ]
       ],
       "shape": {
        "columns": 41,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>year_month</th>\n",
       "      <th>total_expense</th>\n",
       "      <th>txn_count_prev</th>\n",
       "      <th>total_expense_prev</th>\n",
       "      <th>mean_amount</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_current_age</th>\n",
       "      <th>user_yearly_income</th>\n",
       "      <th>user_per_capita_income</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_2_spending</th>\n",
       "      <th>lag_3_spending</th>\n",
       "      <th>lag_5_spending</th>\n",
       "      <th>lag_6_spending</th>\n",
       "      <th>lag_7_spending</th>\n",
       "      <th>lag_9_spending</th>\n",
       "      <th>lag_11_spending</th>\n",
       "      <th>lag_12_spending</th>\n",
       "      <th>1y_holiday_diff</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>5249.9</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6185.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3859.24</td>\n",
       "      <td>6766.18</td>\n",
       "      <td>4266.63</td>\n",
       "      <td>6777.58</td>\n",
       "      <td>6604.68</td>\n",
       "      <td>5055.62</td>\n",
       "      <td>5109.56</td>\n",
       "      <td>6169.59</td>\n",
       "      <td>-1252.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>4229.7</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5249.9</td>\n",
       "      <td>49.2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7091.15</td>\n",
       "      <td>3859.24</td>\n",
       "      <td>5642.49</td>\n",
       "      <td>4266.63</td>\n",
       "      <td>6777.58</td>\n",
       "      <td>7068.70</td>\n",
       "      <td>4600.44</td>\n",
       "      <td>5109.56</td>\n",
       "      <td>-739.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>4595.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4229.7</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4916.87</td>\n",
       "      <td>7091.15</td>\n",
       "      <td>6766.18</td>\n",
       "      <td>5642.49</td>\n",
       "      <td>4266.63</td>\n",
       "      <td>6604.68</td>\n",
       "      <td>5055.62</td>\n",
       "      <td>4600.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4586.5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>4595.4</td>\n",
       "      <td>47.8</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4369.66</td>\n",
       "      <td>4916.87</td>\n",
       "      <td>3859.24</td>\n",
       "      <td>6766.18</td>\n",
       "      <td>5642.49</td>\n",
       "      <td>6777.58</td>\n",
       "      <td>7068.70</td>\n",
       "      <td>5055.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>5864.1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4586.5</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5495.42</td>\n",
       "      <td>4369.66</td>\n",
       "      <td>7091.15</td>\n",
       "      <td>3859.24</td>\n",
       "      <td>6766.18</td>\n",
       "      <td>4266.63</td>\n",
       "      <td>6604.68</td>\n",
       "      <td>7068.70</td>\n",
       "      <td>-1420.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>6104.9</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5864.1</td>\n",
       "      <td>57.6</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4938.54</td>\n",
       "      <td>5495.42</td>\n",
       "      <td>4916.87</td>\n",
       "      <td>7091.15</td>\n",
       "      <td>3859.24</td>\n",
       "      <td>5642.49</td>\n",
       "      <td>6777.58</td>\n",
       "      <td>6604.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>5504.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6104.9</td>\n",
       "      <td>59.8</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5648.13</td>\n",
       "      <td>4938.54</td>\n",
       "      <td>4369.66</td>\n",
       "      <td>4916.87</td>\n",
       "      <td>7091.15</td>\n",
       "      <td>6766.18</td>\n",
       "      <td>4266.63</td>\n",
       "      <td>6777.58</td>\n",
       "      <td>-1133.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>5029.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5504.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5886.93</td>\n",
       "      <td>5648.13</td>\n",
       "      <td>5495.42</td>\n",
       "      <td>4369.66</td>\n",
       "      <td>4916.87</td>\n",
       "      <td>3859.24</td>\n",
       "      <td>5642.49</td>\n",
       "      <td>4266.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>5329.9</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5029.5</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5644.05</td>\n",
       "      <td>5886.93</td>\n",
       "      <td>4938.54</td>\n",
       "      <td>5495.42</td>\n",
       "      <td>4369.66</td>\n",
       "      <td>7091.15</td>\n",
       "      <td>6766.18</td>\n",
       "      <td>5642.49</td>\n",
       "      <td>67.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>6071.2</td>\n",
       "      <td>94.0</td>\n",
       "      <td>5329.9</td>\n",
       "      <td>58.9</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>59613.0</td>\n",
       "      <td>29237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5029.51</td>\n",
       "      <td>5644.05</td>\n",
       "      <td>5648.13</td>\n",
       "      <td>4938.54</td>\n",
       "      <td>5495.42</td>\n",
       "      <td>4916.87</td>\n",
       "      <td>3859.24</td>\n",
       "      <td>6766.18</td>\n",
       "      <td>-495.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  year_month  total_expense  txn_count_prev  total_expense_prev  \\\n",
       "0        0  2015-01-01         5249.9           128.0              6185.2   \n",
       "1        0  2015-02-01         4229.7            99.0              5249.9   \n",
       "2        0  2015-03-01         4595.4            86.0              4229.7   \n",
       "3        0  2015-04-01         4586.5           101.0              4595.4   \n",
       "4        0  2015-05-01         5864.1            96.0              4586.5   \n",
       "5        0  2015-06-01         6104.9           116.0              5864.1   \n",
       "6        0  2015-07-01         5504.0           106.0              6104.9   \n",
       "7        0  2015-08-01         5029.5            92.0              5504.1   \n",
       "8        0  2015-09-01         5329.9           103.0              5029.5   \n",
       "9        0  2015-10-01         6071.2            94.0              5329.9   \n",
       "\n",
       "   mean_amount  user_gender  user_current_age  user_yearly_income  \\\n",
       "0         53.0            0                33             59613.0   \n",
       "1         49.2            0                33             59613.0   \n",
       "2         45.5            0                33             59613.0   \n",
       "3         47.8            0                33             59613.0   \n",
       "4         50.6            0                33             59613.0   \n",
       "5         57.6            0                33             59613.0   \n",
       "6         59.8            0                33             59613.0   \n",
       "7         48.8            0                33             59613.0   \n",
       "8         56.7            0                33             59613.0   \n",
       "9         58.9            0                33             59613.0   \n",
       "\n",
       "   user_per_capita_income  ...  lag_2_spending  lag_3_spending  \\\n",
       "0                 29237.0  ...         3859.24         6766.18   \n",
       "1                 29237.0  ...         7091.15         3859.24   \n",
       "2                 29237.0  ...         4916.87         7091.15   \n",
       "3                 29237.0  ...         4369.66         4916.87   \n",
       "4                 29237.0  ...         5495.42         4369.66   \n",
       "5                 29237.0  ...         4938.54         5495.42   \n",
       "6                 29237.0  ...         5648.13         4938.54   \n",
       "7                 29237.0  ...         5886.93         5648.13   \n",
       "8                 29237.0  ...         5644.05         5886.93   \n",
       "9                 29237.0  ...         5029.51         5644.05   \n",
       "\n",
       "   lag_5_spending  lag_6_spending  lag_7_spending  lag_9_spending  \\\n",
       "0         4266.63         6777.58         6604.68         5055.62   \n",
       "1         5642.49         4266.63         6777.58         7068.70   \n",
       "2         6766.18         5642.49         4266.63         6604.68   \n",
       "3         3859.24         6766.18         5642.49         6777.58   \n",
       "4         7091.15         3859.24         6766.18         4266.63   \n",
       "5         4916.87         7091.15         3859.24         5642.49   \n",
       "6         4369.66         4916.87         7091.15         6766.18   \n",
       "7         5495.42         4369.66         4916.87         3859.24   \n",
       "8         4938.54         5495.42         4369.66         7091.15   \n",
       "9         5648.13         4938.54         5495.42         4916.87   \n",
       "\n",
       "   lag_11_spending  lag_12_spending  1y_holiday_diff  is_holiday  \n",
       "0          5109.56          6169.59         -1252.72           1  \n",
       "1          4600.44          5109.56          -739.90           1  \n",
       "2          5055.62          4600.44             0.00           0  \n",
       "3          7068.70          5055.62             0.00           0  \n",
       "4          6604.68          7068.70         -1420.57           1  \n",
       "5          6777.58          6604.68             0.00           0  \n",
       "6          4266.63          6777.58         -1133.53           1  \n",
       "7          5642.49          4266.63             0.00           0  \n",
       "8          6766.18          5642.49            67.42           1  \n",
       "9          3859.24          6766.18          -495.02           1  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sequence_with_lag_features_cancel_out_total_amount.csv')  \n",
    "df['is_holiday'] = df['is_holiday'].replace({False: 0, True: 1})\n",
    "df['1y_holiday_diff'] = df['1y_holiday_diff'].fillna(0)\n",
    "df['lag_1_spending'] = df['lag_1_spending'].fillna(0)\n",
    "df['lag_2_spending'] = df['lag_2_spending'].fillna(0)\n",
    "df['lag_3_spending'] = df['lag_3_spending'].fillna(0)\n",
    "df['lag_5_spending'] = df['lag_5_spending'].fillna(0)\n",
    "df['lag_6_spending'] = df['lag_6_spending'].fillna(0)\n",
    "df['lag_7_spending'] = df['lag_7_spending'].fillna(0)\n",
    "df['lag_9_spending'] = df['lag_9_spending'].fillna(0)\n",
    "df['lag_11_spending'] = df['lag_11_spending'].fillna(0)\n",
    "df['lag_12_spending'] = df['lag_12_spending'].fillna(0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9823c8ee-8c1a-4b86-bffd-cd93628a101f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43305 14454 10852\n"
     ]
    }
   ],
   "source": [
    "df['year_month'] = pd.to_datetime(df['year_month'])\n",
    "df = df.rename(columns={'total_expense': 'total_spending'})  \n",
    "\n",
    "'''\n",
    "The new setup for datasets and dataloaders\n",
    "'''\n",
    "\n",
    "train_end = pd.Timestamp('2017-12-31')\n",
    "val_end = pd.Timestamp('2018-12-31')\n",
    "test_end = pd.Timestamp('2019-09-30')\n",
    "\n",
    "train_mask = df['year_month'] <= train_end\n",
    "val_mask = (df['year_month'] > train_end) & (df['year_month'] <= val_end)\n",
    "test_mask = (df['year_month'] > val_end) & (df['year_month'] <= test_end)\n",
    "\n",
    "train_df = df.loc[train_mask].copy()\n",
    "val_df = df.loc[val_mask].copy()\n",
    "test_df = df.loc[test_mask].copy()\n",
    "\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0bf290d-8bdb-49f6-837b-67a4656ec5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols = ['total_expense_prev',\n",
    "    'mean_amount','user_yearly_income',\n",
    "       'user_per_capita_income','user_credit_score', 'user_total_debt','income_per_card','lag_1_spending',\n",
    "       'lag_2_spending', 'lag_3_spending', 'lag_5_spending', 'lag_6_spending',\n",
    "       'lag_7_spending', 'lag_9_spending', 'lag_11_spending',\n",
    "       'lag_12_spending'\n",
    "]\n",
    "# --- normalize ---\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[num_cols])\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled[num_cols] = scaler.transform(df_scaled[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732c4157-ef58-4dd9-8117-d1b79821068a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TransactionDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, user_col='user_id', date_col='year_month',\n",
    "                 target_col='total_spending', window_size=12,\n",
    "                 target_start=None, target_end=None):\n",
    "        self.feature_cols = feature_cols\n",
    "        self.user_col = user_col\n",
    "        self.date_col = date_col\n",
    "        self.target_col = target_col\n",
    "        self.window_size = window_size\n",
    "        self.samples = []\n",
    "\n",
    "\n",
    "        ts = pd.to_datetime(target_start) if target_start is not None else None\n",
    "        te = pd.to_datetime(target_end)   if target_end   is not None else None\n",
    "        if ts is None: ts = df[date_col].min()\n",
    "        if te is None: te = df[date_col].max()\n",
    "\n",
    "\n",
    "        for _, g in df.groupby(user_col):\n",
    "            '''\n",
    "            We use previous 12 months of data to predict the target month, even if the history \n",
    "            crosses the train/val/test boundaries\n",
    "            '''\n",
    "            g = g.sort_values(date_col).reset_index(drop=True)\n",
    "            Xmat = g[self.feature_cols].to_numpy(dtype=float)\n",
    "            yvec = g[self.target_col].to_numpy(dtype=float)\n",
    "            months = g[date_col].to_numpy()\n",
    "\n",
    "            for i in range(window_size, len(g)):\n",
    "                t_month = months[i]\n",
    "                if t_month < ts or t_month > te:\n",
    "                    continue\n",
    "                X = Xmat[i-window_size:i]\n",
    "                y = float(yvec[i])\n",
    "                self.samples.append((X, y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.samples[idx]\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            torch.tensor(y, dtype=torch.float32)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21280948-cca6-48f8-864b-437a2493354d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMAmountPredictor(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim=128, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,   \n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len, num_features]\n",
    "        out, _ = self.lstm(x)\n",
    "        last_out = out[:, -1, :]  # [batch, hidden_dim]\n",
    "        y_pred = self.fc(last_out)  # [batch, 1]\n",
    "        return y_pred.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227bfe8a-8445-4d7f-870d-684a171fe082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'txn_count_prev', 'mean_amount','total_expense_prev',\n",
    "       'user_gender', 'user_current_age', 'user_yearly_income',\n",
    "       'user_per_capita_income', 'user_credit_score', 'user_total_debt',\n",
    "       'user_birth_month', 'card_num_cards_issued', 'user_latitude',\n",
    "       'user_longitude', 'year_to_retirement', 'debt_to_yearly_income_ratio',\n",
    "       'income_per_card', 'multi_card_user', 'income_utilization_ratio',\n",
    "       'credit_utilization_ratio', 'oldest_card_age_years',\n",
    "       'weekend_spend_ratio', 'correlation_with_trend',\n",
    "       'risk_of_default_score', 'risk_level', 'Cluster',\n",
    "       'percentage_prev_monthly_expense_as_yearly',\n",
    "       'percentage_prev_monthly_expense_as_capita', 'lag_1_spending',\n",
    "       'lag_2_spending', 'lag_3_spending', 'lag_5_spending', 'lag_6_spending',\n",
    "       'lag_7_spending', 'lag_9_spending', 'lag_11_spending',\n",
    "       'lag_12_spending', '1y_holiday_diff', 'is_holiday'\n",
    "]\n",
    "\n",
    "\n",
    "'''\n",
    "The new setup for datasets and dataloaders\n",
    "'''\n",
    "train_target_start= df['year_month'].min() + pd.offsets.MonthBegin(0)\n",
    "train_target_end= train_end\n",
    "val_target_start= train_end + pd.offsets.Day(1)\n",
    "val_target_end= val_end\n",
    "test_target_start= val_end + pd.offsets.Day(1)\n",
    "test_target_end= test_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c41073-efc9-48c9-899e-9b6feea74454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "num_features = len(feature_cols)\n",
    "model = LSTMAmountPredictor(num_features=num_features, hidden_dim=128, num_layers=2)\n",
    "# hyperparam\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 250\n",
    "LR = 1e-3\n",
    "PATIENCE = 20   \n",
    "\n",
    "'''\n",
    "The new setup for datasets and dataloaders\n",
    "'''\n",
    "train_dataset = TransactionDataset(\n",
    "    df=df_scaled, feature_cols=feature_cols, window_size=12,\n",
    "    target_start=train_target_start, target_end=train_target_end,\n",
    "    target_col='total_spending'\n",
    ")\n",
    "val_dataset = TransactionDataset(\n",
    "    df=df_scaled, feature_cols=feature_cols, window_size=12,\n",
    "    target_start=val_target_start, target_end=val_target_end,\n",
    "    target_col='total_spending'\n",
    ")\n",
    "test_dataset = TransactionDataset(\n",
    "    df=df_scaled, feature_cols=feature_cols, window_size=12,\n",
    "    target_start=test_target_start, target_end=test_target_end,\n",
    "    target_col='total_spending'\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "best_val_loss = np.inf\n",
    "patience_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebf39436-043e-475b-a540-4fda902a126f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 164.57it/s]\n",
      "Epoch 1/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 461.03it/s]\n",
      "Epoch 1/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 526.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 01 | Train Loss: 21560505.168889 | Val Loss: 21300008.398230 | test Loss: 20955394.352941\n",
      "âœ… Saved new best model (val_loss=21300008.398230)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 189.20it/s]\n",
      "Epoch 2/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 496.37it/s]\n",
      "Epoch 2/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 504.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 02 | Train Loss: 21337111.857778 | Val Loss: 21073172.942478 | test Loss: 20730046.341176\n",
      "âœ… Saved new best model (val_loss=21073172.942478)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 198.63it/s]\n",
      "Epoch 3/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 441.56it/s]\n",
      "Epoch 3/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 508.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 03 | Train Loss: 21096510.253333 | Val Loss: 20852181.938053 | test Loss: 20510514.200000\n",
      "âœ… Saved new best model (val_loss=20852181.938053)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 193.45it/s]\n",
      "Epoch 4/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 473.37it/s]\n",
      "Epoch 4/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 04 | Train Loss: 20883019.204444 | Val Loss: 20634573.774336 | test Loss: 20294353.376471\n",
      "âœ… Saved new best model (val_loss=20634573.774336)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 177.63it/s]\n",
      "Epoch 5/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 486.61it/s]\n",
      "Epoch 5/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 454.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 05 | Train Loss: 20659604.222222 | Val Loss: 20419766.106195 | test Loss: 20080985.111765\n",
      "âœ… Saved new best model (val_loss=20419766.106195)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.10it/s]\n",
      "Epoch 6/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 491.71it/s]\n",
      "Epoch 6/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 427.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 06 | Train Loss: 20460259.133333 | Val Loss: 20207609.500000 | test Loss: 19870261.270588\n",
      "âœ… Saved new best model (val_loss=20207609.500000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 178.52it/s]\n",
      "Epoch 7/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 472.91it/s]\n",
      "Epoch 7/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 07 | Train Loss: 20235731.391111 | Val Loss: 19997592.831858 | test Loss: 19661673.729412\n",
      "âœ… Saved new best model (val_loss=19997592.831858)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 167.31it/s]\n",
      "Epoch 8/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 387.25it/s]\n",
      "Epoch 8/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 382.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 08 | Train Loss: 20031862.253333 | Val Loss: 19789882.730088 | test Loss: 19455387.917647\n",
      "âœ… Saved new best model (val_loss=19789882.730088)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 162.06it/s]\n",
      "Epoch 9/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 458.77it/s]\n",
      "Epoch 9/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 448.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 09 | Train Loss: 19819909.866667 | Val Loss: 19584345.039823 | test Loss: 19251270.258824\n",
      "âœ… Saved new best model (val_loss=19584345.039823)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 164.90it/s]\n",
      "Epoch 10/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 424.28it/s]\n",
      "Epoch 10/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 10 | Train Loss: 19618747.333333 | Val Loss: 19380791.650442 | test Loss: 19049134.517647\n",
      "âœ… Saved new best model (val_loss=19380791.650442)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.99it/s]\n",
      "Epoch 11/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.32it/s]\n",
      "Epoch 11/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 11 | Train Loss: 19418577.160000 | Val Loss: 19179300.008850 | test Loss: 18849056.829412\n",
      "âœ… Saved new best model (val_loss=19179300.008850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.81it/s]\n",
      "Epoch 12/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.28it/s]\n",
      "Epoch 12/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 12 | Train Loss: 19214006.337778 | Val Loss: 18979290.654867 | test Loss: 18650461.929412\n",
      "âœ… Saved new best model (val_loss=18979290.654867)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.78it/s]\n",
      "Epoch 13/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 414.52it/s]\n",
      "Epoch 13/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 448.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 13 | Train Loss: 19012059.991111 | Val Loss: 18781404.106195 | test Loss: 18453986.288235\n",
      "âœ… Saved new best model (val_loss=18781404.106195)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.56it/s]\n",
      "Epoch 14/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.80it/s]\n",
      "Epoch 14/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 14 | Train Loss: 18813826.240000 | Val Loss: 18585238.176991 | test Loss: 18259229.600000\n",
      "âœ… Saved new best model (val_loss=18585238.176991)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.57it/s]\n",
      "Epoch 15/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.26it/s]\n",
      "Epoch 15/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 15 | Train Loss: 18621526.564444 | Val Loss: 18391162.415929 | test Loss: 18066559.782353\n",
      "âœ… Saved new best model (val_loss=18391162.415929)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 178.54it/s]\n",
      "Epoch 16/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.00it/s]\n",
      "Epoch 16/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 454.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 16 | Train Loss: 18426842.604444 | Val Loss: 18198701.101770 | test Loss: 17875503.405882\n",
      "âœ… Saved new best model (val_loss=18198701.101770)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.37it/s]\n",
      "Epoch 17/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.02it/s]\n",
      "Epoch 17/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 17 | Train Loss: 18230205.222222 | Val Loss: 18007700.902655 | test Loss: 17685909.335294\n",
      "âœ… Saved new best model (val_loss=18007700.902655)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 177.64it/s]\n",
      "Epoch 18/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 485.31it/s]\n",
      "Epoch 18/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 477.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 18 | Train Loss: 18038408.715556 | Val Loss: 17818730.088496 | test Loss: 17498340.788235\n",
      "âœ… Saved new best model (val_loss=17818730.088496)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 189.20it/s]\n",
      "Epoch 19/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 462.70it/s]\n",
      "Epoch 19/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 473.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 19 | Train Loss: 17855919.422222 | Val Loss: 17631297.292035 | test Loss: 17312310.405882\n",
      "âœ… Saved new best model (val_loss=17631297.292035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.95it/s]\n",
      "Epoch 20/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 447.55it/s]\n",
      "Epoch 20/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 20 | Train Loss: 17666625.875556 | Val Loss: 17445633.234513 | test Loss: 17128046.976471\n",
      "âœ… Saved new best model (val_loss=17445633.234513)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 166.57it/s]\n",
      "Epoch 21/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 424.06it/s]\n",
      "Epoch 21/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 350.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 21 | Train Loss: 17482215.986667 | Val Loss: 17261672.778761 | test Loss: 16945486.135294\n",
      "âœ… Saved new best model (val_loss=17261672.778761)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.03it/s]\n",
      "Epoch 22/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.48it/s]\n",
      "Epoch 22/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 22 | Train Loss: 17296353.928889 | Val Loss: 17078955.353982 | test Loss: 16764170.388235\n",
      "âœ… Saved new best model (val_loss=17078955.353982)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.94it/s]\n",
      "Epoch 23/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.89it/s]\n",
      "Epoch 23/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 453.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 23 | Train Loss: 17112736.737778 | Val Loss: 16898195.234513 | test Loss: 16584808.670588\n",
      "âœ… Saved new best model (val_loss=16898195.234513)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.96it/s]\n",
      "Epoch 24/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 442.41it/s]\n",
      "Epoch 24/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 436.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 24 | Train Loss: 16933119.555556 | Val Loss: 16719245.836283 | test Loss: 16407255.735294\n",
      "âœ… Saved new best model (val_loss=16719245.836283)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 167.65it/s]\n",
      "Epoch 25/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 447.44it/s]\n",
      "Epoch 25/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 457.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 25 | Train Loss: 16756560.951111 | Val Loss: 16541505.048673 | test Loss: 16230913.952941\n",
      "âœ… Saved new best model (val_loss=16541505.048673)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 179.71it/s]\n",
      "Epoch 26/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 491.89it/s]\n",
      "Epoch 26/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 486.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 26 | Train Loss: 16581138.217778 | Val Loss: 16365864.188053 | test Loss: 16056667.482353\n",
      "âœ… Saved new best model (val_loss=16365864.188053)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.96it/s]\n",
      "Epoch 27/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 453.13it/s]\n",
      "Epoch 27/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 427.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 27 | Train Loss: 16404202.008889 | Val Loss: 16191606.057522 | test Loss: 15883804.729412\n",
      "âœ… Saved new best model (val_loss=16191606.057522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 164.08it/s]\n",
      "Epoch 28/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 491.11it/s]\n",
      "Epoch 28/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 28 | Train Loss: 16229389.640000 | Val Loss: 16018909.486726 | test Loss: 15712506.182353\n",
      "âœ… Saved new best model (val_loss=16018909.486726)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.06it/s]\n",
      "Epoch 29/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 441.16it/s]\n",
      "Epoch 29/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 422.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 29 | Train Loss: 16055617.013333 | Val Loss: 15847713.008850 | test Loss: 15542734.158824\n",
      "âœ… Saved new best model (val_loss=15847713.008850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 161.58it/s]\n",
      "Epoch 30/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.01it/s]\n",
      "Epoch 30/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 400.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 30 | Train Loss: 15887375.293333 | Val Loss: 15678335.369469 | test Loss: 15374750.882353\n",
      "âœ… Saved new best model (val_loss=15678335.369469)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 159.64it/s]\n",
      "Epoch 31/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 395.18it/s]\n",
      "Epoch 31/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 406.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 31 | Train Loss: 15722386.342222 | Val Loss: 15510271.287611 | test Loss: 15208087.011765\n",
      "âœ… Saved new best model (val_loss=15510271.287611)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 162.48it/s]\n",
      "Epoch 32/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 406.56it/s]\n",
      "Epoch 32/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 399.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 32 | Train Loss: 15550503.128889 | Val Loss: 15344007.497788 | test Loss: 15043217.082353\n",
      "âœ… Saved new best model (val_loss=15344007.497788)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 158.26it/s]\n",
      "Epoch 33/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.36it/s]\n",
      "Epoch 33/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 488.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 33 | Train Loss: 15384875.337778 | Val Loss: 15179190.382743 | test Loss: 14879801.911765\n",
      "âœ… Saved new best model (val_loss=15179190.382743)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.38it/s]\n",
      "Epoch 34/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.47it/s]\n",
      "Epoch 34/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 456.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 34 | Train Loss: 15222595.088889 | Val Loss: 15012292.077434 | test Loss: 14714342.117647\n",
      "âœ… Saved new best model (val_loss=15012292.077434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.95it/s]\n",
      "Epoch 35/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 462.90it/s]\n",
      "Epoch 35/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 465.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 35 | Train Loss: 15060812.151111 | Val Loss: 14848056.477876 | test Loss: 14551523.082353\n",
      "âœ… Saved new best model (val_loss=14848056.477876)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.06it/s]\n",
      "Epoch 36/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 440.76it/s]\n",
      "Epoch 36/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 424.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 36 | Train Loss: 14890115.506667 | Val Loss: 14685810.256637 | test Loss: 14390689.864706\n",
      "âœ… Saved new best model (val_loss=14685810.256637)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 158.26it/s]\n",
      "Epoch 37/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 421.62it/s]\n",
      "Epoch 37/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 394.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 37 | Train Loss: 14722566.880000 | Val Loss: 14525848.422566 | test Loss: 14232135.900000\n",
      "âœ… Saved new best model (val_loss=14525848.422566)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 162.32it/s]\n",
      "Epoch 38/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 462.66it/s]\n",
      "Epoch 38/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 450.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 38 | Train Loss: 14564124.900000 | Val Loss: 14367680.725664 | test Loss: 14075378.932353\n",
      "âœ… Saved new best model (val_loss=14367680.725664)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 165.95it/s]\n",
      "Epoch 39/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.62it/s]\n",
      "Epoch 39/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 39 | Train Loss: 14404924.497778 | Val Loss: 14211030.652655 | test Loss: 13920133.635294\n",
      "âœ… Saved new best model (val_loss=14211030.652655)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 159.65it/s]\n",
      "Epoch 40/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 447.87it/s]\n",
      "Epoch 40/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 40 | Train Loss: 14250785.306667 | Val Loss: 14056293.918142 | test Loss: 13766801.829412\n",
      "âœ… Saved new best model (val_loss=14056293.918142)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.54it/s]\n",
      "Epoch 41/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 471.15it/s]\n",
      "Epoch 41/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 41 | Train Loss: 14095899.253333 | Val Loss: 13903181.221239 | test Loss: 13615092.770588\n",
      "âœ… Saved new best model (val_loss=13903181.221239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.34it/s]\n",
      "Epoch 42/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 486.84it/s]\n",
      "Epoch 42/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 493.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 42 | Train Loss: 13945628.977778 | Val Loss: 13751604.314159 | test Loss: 13464916.991176\n",
      "âœ… Saved new best model (val_loss=13751604.314159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.43it/s]\n",
      "Epoch 43/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 462.21it/s]\n",
      "Epoch 43/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 461.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 43 | Train Loss: 13796809.944444 | Val Loss: 13601740.502212 | test Loss: 13316453.952941\n",
      "âœ… Saved new best model (val_loss=13601740.502212)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.22it/s]\n",
      "Epoch 44/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 476.72it/s]\n",
      "Epoch 44/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 486.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 44 | Train Loss: 13649986.560000 | Val Loss: 13454065.318584 | test Loss: 13170282.555882\n",
      "âœ… Saved new best model (val_loss=13454065.318584)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.26it/s]\n",
      "Epoch 45/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 446.26it/s]\n",
      "Epoch 45/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 454.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 45 | Train Loss: 13496402.686667 | Val Loss: 13306671.707965 | test Loss: 13024197.382353\n",
      "âœ… Saved new best model (val_loss=13306671.707965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 184.66it/s]\n",
      "Epoch 46/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 465.85it/s]\n",
      "Epoch 46/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 451.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 46 | Train Loss: 13351761.126667 | Val Loss: 13161371.975664 | test Loss: 12880293.085294\n",
      "âœ… Saved new best model (val_loss=13161371.975664)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.75it/s]\n",
      "Epoch 47/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 458.95it/s]\n",
      "Epoch 47/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 435.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 47 | Train Loss: 13199511.851111 | Val Loss: 13012788.314159 | test Loss: 12733791.211765\n",
      "âœ… Saved new best model (val_loss=13012788.314159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.62it/s]\n",
      "Epoch 48/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 452.71it/s]\n",
      "Epoch 48/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 429.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 48 | Train Loss: 13061627.700000 | Val Loss: 12869751.891593 | test Loss: 12592621.820588\n",
      "âœ… Saved new best model (val_loss=12869751.891593)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 183.06it/s]\n",
      "Epoch 49/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 474.25it/s]\n",
      "Epoch 49/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 478.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 49 | Train Loss: 12917229.120000 | Val Loss: 12728355.342920 | test Loss: 12452660.582353\n",
      "âœ… Saved new best model (val_loss=12728355.342920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.49it/s]\n",
      "Epoch 50/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 462.58it/s]\n",
      "Epoch 50/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 444.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 50 | Train Loss: 12772506.500000 | Val Loss: 12588480.004425 | test Loss: 12314205.700000\n",
      "âœ… Saved new best model (val_loss=12588480.004425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.15it/s]\n",
      "Epoch 51/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 433.31it/s]\n",
      "Epoch 51/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 432.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 51 | Train Loss: 12635051.440000 | Val Loss: 12450959.446903 | test Loss: 12177934.026471\n",
      "âœ… Saved new best model (val_loss=12450959.446903)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.37it/s]\n",
      "Epoch 52/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 490.45it/s]\n",
      "Epoch 52/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 52 | Train Loss: 12492349.848889 | Val Loss: 12313830.851770 | test Loss: 12042337.441176\n",
      "âœ… Saved new best model (val_loss=12313830.851770)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 189.49it/s]\n",
      "Epoch 53/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.45it/s]\n",
      "Epoch 53/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 449.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 53 | Train Loss: 12358564.357778 | Val Loss: 12179234.975664 | test Loss: 11909033.814706\n",
      "âœ… Saved new best model (val_loss=12179234.975664)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.74it/s]\n",
      "Epoch 54/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 447.96it/s]\n",
      "Epoch 54/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 449.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 54 | Train Loss: 12220145.595556 | Val Loss: 12046011.095133 | test Loss: 11777166.005882\n",
      "âœ… Saved new best model (val_loss=12046011.095133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.76it/s]\n",
      "Epoch 55/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 424.43it/s]\n",
      "Epoch 55/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 412.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 55 | Train Loss: 12088410.797778 | Val Loss: 11913256.391593 | test Loss: 11645985.220588\n",
      "âœ… Saved new best model (val_loss=11913256.391593)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 178.01it/s]\n",
      "Epoch 56/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 490.10it/s]\n",
      "Epoch 56/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 56 | Train Loss: 11962387.333333 | Val Loss: 11782675.075221 | test Loss: 11516568.147059\n",
      "âœ… Saved new best model (val_loss=11782675.075221)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.28it/s]\n",
      "Epoch 57/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 451.42it/s]\n",
      "Epoch 57/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 447.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 57 | Train Loss: 11827745.535556 | Val Loss: 11653462.996681 | test Loss: 11388770.700000\n",
      "âœ… Saved new best model (val_loss=11653462.996681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.87it/s]\n",
      "Epoch 58/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 407.02it/s]\n",
      "Epoch 58/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 58 | Train Loss: 11696922.704444 | Val Loss: 11525097.728982 | test Loss: 11261441.491176\n",
      "âœ… Saved new best model (val_loss=11525097.728982)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.28it/s]\n",
      "Epoch 59/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 490.91it/s]\n",
      "Epoch 59/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 481.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 59 | Train Loss: 11566792.444444 | Val Loss: 11398938.901549 | test Loss: 11136301.094118\n",
      "âœ… Saved new best model (val_loss=11398938.901549)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 187.66it/s]\n",
      "Epoch 60/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 449.46it/s]\n",
      "Epoch 60/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 473.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 60 | Train Loss: 11447667.760000 | Val Loss: 11278900.777655 | test Loss: 11018755.147059\n",
      "âœ… Saved new best model (val_loss=11278900.777655)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.71it/s]\n",
      "Epoch 61/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 453.14it/s]\n",
      "Epoch 61/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 449.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 61 | Train Loss: 11319114.297778 | Val Loss: 11150469.024336 | test Loss: 10891444.591176\n",
      "âœ… Saved new best model (val_loss=11150469.024336)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.37it/s]\n",
      "Epoch 62/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.32it/s]\n",
      "Epoch 62/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 441.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 62 | Train Loss: 11198696.288889 | Val Loss: 11028282.377212 | test Loss: 10769899.111765\n",
      "âœ… Saved new best model (val_loss=11028282.377212)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.13it/s]\n",
      "Epoch 63/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.25it/s]\n",
      "Epoch 63/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 501.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 63 | Train Loss: 11073348.448889 | Val Loss: 10907530.155973 | test Loss: 10650602.408824\n",
      "âœ… Saved new best model (val_loss=10907530.155973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 184.78it/s]\n",
      "Epoch 64/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.97it/s]\n",
      "Epoch 64/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 64 | Train Loss: 10950224.020000 | Val Loss: 10788274.173673 | test Loss: 10532179.464706\n",
      "âœ… Saved new best model (val_loss=10788274.173673)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 167.30it/s]\n",
      "Epoch 65/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.16it/s]\n",
      "Epoch 65/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 448.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 65 | Train Loss: 10829445.300000 | Val Loss: 10671540.334071 | test Loss: 10417516.726471\n",
      "âœ… Saved new best model (val_loss=10671540.334071)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.05it/s]\n",
      "Epoch 66/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 433.95it/s]\n",
      "Epoch 66/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 66 | Train Loss: 10714185.695556 | Val Loss: 10554129.435841 | test Loss: 10300175.488235\n",
      "âœ… Saved new best model (val_loss=10554129.435841)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.86it/s]\n",
      "Epoch 67/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 451.37it/s]\n",
      "Epoch 67/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 465.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 67 | Train Loss: 10596464.802222 | Val Loss: 10439617.491150 | test Loss: 10187566.805882\n",
      "âœ… Saved new best model (val_loss=10439617.491150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.78it/s]\n",
      "Epoch 68/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 447.44it/s]\n",
      "Epoch 68/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 389.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 68 | Train Loss: 10489778.042222 | Val Loss: 10326213.550885 | test Loss: 10074914.352941\n",
      "âœ… Saved new best model (val_loss=10326213.550885)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.43it/s]\n",
      "Epoch 69/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 474.75it/s]\n",
      "Epoch 69/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 478.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 69 | Train Loss: 10367526.668889 | Val Loss: 10211576.448009 | test Loss: 9962250.872059\n",
      "âœ… Saved new best model (val_loss=10211576.448009)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 178.26it/s]\n",
      "Epoch 70/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 461.76it/s]\n",
      "Epoch 70/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 441.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 70 | Train Loss: 10250141.566667 | Val Loss: 10100141.431416 | test Loss: 9852028.095588\n",
      "âœ… Saved new best model (val_loss=10100141.431416)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.37it/s]\n",
      "Epoch 71/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 413.35it/s]\n",
      "Epoch 71/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 370.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 71 | Train Loss: 10149336.017778 | Val Loss: 9991511.485619 | test Loss: 9744345.102941\n",
      "âœ… Saved new best model (val_loss=9991511.485619)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 188.38it/s]\n",
      "Epoch 72/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 482.76it/s]\n",
      "Epoch 72/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 497.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 72 | Train Loss: 10038622.642222 | Val Loss: 9882465.017699 | test Loss: 9637287.326471\n",
      "âœ… Saved new best model (val_loss=9882465.017699)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.00it/s]\n",
      "Epoch 73/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 460.50it/s]\n",
      "Epoch 73/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 459.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 73 | Train Loss: 9933215.713333 | Val Loss: 9775419.022124 | test Loss: 9530080.758824\n",
      "âœ… Saved new best model (val_loss=9775419.022124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.54it/s]\n",
      "Epoch 74/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.15it/s]\n",
      "Epoch 74/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 74 | Train Loss: 9813254.735556 | Val Loss: 9668356.950221 | test Loss: 9425002.004412\n",
      "âœ… Saved new best model (val_loss=9668356.950221)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 166.54it/s]\n",
      "Epoch 75/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 361.21it/s]\n",
      "Epoch 75/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 75 | Train Loss: 9710461.591111 | Val Loss: 9563110.073009 | test Loss: 9321814.788235\n",
      "âœ… Saved new best model (val_loss=9563110.073009)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 184.59it/s]\n",
      "Epoch 76/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 469.96it/s]\n",
      "Epoch 76/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 76 | Train Loss: 9605911.240000 | Val Loss: 9461178.261062 | test Loss: 9222260.882353\n",
      "âœ… Saved new best model (val_loss=9461178.261062)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.46it/s]\n",
      "Epoch 77/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.22it/s]\n",
      "Epoch 77/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 77 | Train Loss: 9505626.846667 | Val Loss: 9357809.862832 | test Loss: 9117061.760294\n",
      "âœ… Saved new best model (val_loss=9357809.862832)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.61it/s]\n",
      "Epoch 78/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.68it/s]\n",
      "Epoch 78/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 327.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 78 | Train Loss: 9397970.931111 | Val Loss: 9255064.659292 | test Loss: 9016585.711765\n",
      "âœ… Saved new best model (val_loss=9255064.659292)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 186.58it/s]\n",
      "Epoch 79/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 492.60it/s]\n",
      "Epoch 79/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 478.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 79 | Train Loss: 9297546.601111 | Val Loss: 9154908.886062 | test Loss: 8918246.470588\n",
      "âœ… Saved new best model (val_loss=9154908.886062)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.16it/s]\n",
      "Epoch 80/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 436.43it/s]\n",
      "Epoch 80/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 80 | Train Loss: 9200214.677778 | Val Loss: 9056448.608407 | test Loss: 8820374.933824\n",
      "âœ… Saved new best model (val_loss=9056448.608407)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.86it/s]\n",
      "Epoch 81/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 452.83it/s]\n",
      "Epoch 81/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 444.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 81 | Train Loss: 9102628.860000 | Val Loss: 8959180.498341 | test Loss: 8724059.289706\n",
      "âœ… Saved new best model (val_loss=8959180.498341)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.15it/s]\n",
      "Epoch 82/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 425.77it/s]\n",
      "Epoch 82/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 435.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 82 | Train Loss: 9004879.368889 | Val Loss: 8861760.356748 | test Loss: 8628161.750000\n",
      "âœ… Saved new best model (val_loss=8861760.356748)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 179.98it/s]\n",
      "Epoch 83/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 482.30it/s]\n",
      "Epoch 83/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 504.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 83 | Train Loss: 8904171.451111 | Val Loss: 8769140.835730 | test Loss: 8535920.336765\n",
      "âœ… Saved new best model (val_loss=8769140.835730)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 177.64it/s]\n",
      "Epoch 84/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 433.58it/s]\n",
      "Epoch 84/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 443.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 84 | Train Loss: 8807231.984444 | Val Loss: 8672683.504425 | test Loss: 8441733.366176\n",
      "âœ… Saved new best model (val_loss=8672683.504425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.73it/s]\n",
      "Epoch 85/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.14it/s]\n",
      "Epoch 85/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 85 | Train Loss: 8712108.128889 | Val Loss: 8579724.604535 | test Loss: 8349268.239706\n",
      "âœ… Saved new best model (val_loss=8579724.604535)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 167.56it/s]\n",
      "Epoch 86/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 398.49it/s]\n",
      "Epoch 86/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 401.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 86 | Train Loss: 8620149.474444 | Val Loss: 8489587.131084 | test Loss: 8261019.638235\n",
      "âœ… Saved new best model (val_loss=8489587.131084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 185.22it/s]\n",
      "Epoch 87/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.05it/s]\n",
      "Epoch 87/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 470.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 87 | Train Loss: 8526842.762222 | Val Loss: 8396367.476770 | test Loss: 8167514.001471\n",
      "âœ… Saved new best model (val_loss=8396367.476770)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.38it/s]\n",
      "Epoch 88/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 459.63it/s]\n",
      "Epoch 88/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 439.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 88 | Train Loss: 8435321.645556 | Val Loss: 8305363.228429 | test Loss: 8078534.600000\n",
      "âœ… Saved new best model (val_loss=8305363.228429)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.07it/s]\n",
      "Epoch 89/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.04it/s]\n",
      "Epoch 89/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 360.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 89 | Train Loss: 8345069.598889 | Val Loss: 8216947.119469 | test Loss: 7990748.055882\n",
      "âœ… Saved new best model (val_loss=8216947.119469)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.58it/s]\n",
      "Epoch 90/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 490.96it/s]\n",
      "Epoch 90/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 470.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 90 | Train Loss: 8255335.037778 | Val Loss: 8129224.131637 | test Loss: 7903528.135294\n",
      "âœ… Saved new best model (val_loss=8129224.131637)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.36it/s]\n",
      "Epoch 91/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.12it/s]\n",
      "Epoch 91/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 460.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 91 | Train Loss: 8168696.095556 | Val Loss: 8042823.954646 | test Loss: 7818896.001471\n",
      "âœ… Saved new best model (val_loss=8042823.954646)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.70it/s]\n",
      "Epoch 92/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.96it/s]\n",
      "Epoch 92/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 92 | Train Loss: 8079026.276667 | Val Loss: 7956910.389381 | test Loss: 7735324.830882\n",
      "âœ… Saved new best model (val_loss=7956910.389381)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.89it/s]\n",
      "Epoch 93/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 484.22it/s]\n",
      "Epoch 93/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 93 | Train Loss: 7999586.084444 | Val Loss: 7874531.346239 | test Loss: 7654094.170588\n",
      "âœ… Saved new best model (val_loss=7874531.346239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 185.69it/s]\n",
      "Epoch 94/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.17it/s]\n",
      "Epoch 94/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 460.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 94 | Train Loss: 7909519.435556 | Val Loss: 7787887.599558 | test Loss: 7568307.980882\n",
      "âœ… Saved new best model (val_loss=7787887.599558)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.41it/s]\n",
      "Epoch 95/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 446.83it/s]\n",
      "Epoch 95/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 443.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 95 | Train Loss: 7825253.397778 | Val Loss: 7705614.160398 | test Loss: 7485932.191176\n",
      "âœ… Saved new best model (val_loss=7705614.160398)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.77it/s]\n",
      "Epoch 96/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 440.36it/s]\n",
      "Epoch 96/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 338.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 96 | Train Loss: 7746522.226667 | Val Loss: 7623096.921460 | test Loss: 7405516.943382\n",
      "âœ… Saved new best model (val_loss=7623096.921460)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 189.16it/s]\n",
      "Epoch 97/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 504.12it/s]\n",
      "Epoch 97/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 500.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 97 | Train Loss: 7655500.498889 | Val Loss: 7542361.285398 | test Loss: 7324977.850000\n",
      "âœ… Saved new best model (val_loss=7542361.285398)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 183.26it/s]\n",
      "Epoch 98/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 476.06it/s]\n",
      "Epoch 98/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 455.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 98 | Train Loss: 7589305.872222 | Val Loss: 7464857.919248 | test Loss: 7248974.338235\n",
      "âœ… Saved new best model (val_loss=7464857.919248)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.54it/s]\n",
      "Epoch 99/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 425.32it/s]\n",
      "Epoch 99/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 431.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 99 | Train Loss: 7499735.098889 | Val Loss: 7384551.944137 | test Loss: 7167542.996324\n",
      "âœ… Saved new best model (val_loss=7384551.944137)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.10it/s]\n",
      "Epoch 100/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 351.57it/s]\n",
      "Epoch 100/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 100 | Train Loss: 7420447.486667 | Val Loss: 7304984.247235 | test Loss: 7089953.232353\n",
      "âœ… Saved new best model (val_loss=7304984.247235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 189.35it/s]\n",
      "Epoch 101/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 494.79it/s]\n",
      "Epoch 101/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 101 | Train Loss: 7339300.657778 | Val Loss: 7233379.512721 | test Loss: 7015987.555882\n",
      "âœ… Saved new best model (val_loss=7233379.512721)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.30it/s]\n",
      "Epoch 102/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.50it/s]\n",
      "Epoch 102/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 447.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 102 | Train Loss: 7260807.831111 | Val Loss: 7154385.895465 | test Loss: 6939489.901471\n",
      "âœ… Saved new best model (val_loss=7154385.895465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.43it/s]\n",
      "Epoch 103/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.65it/s]\n",
      "Epoch 103/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 432.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 103 | Train Loss: 7186520.471111 | Val Loss: 7078892.627212 | test Loss: 6868385.030882\n",
      "âœ… Saved new best model (val_loss=7078892.627212)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 176.01it/s]\n",
      "Epoch 104/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 504.12it/s]\n",
      "Epoch 104/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 104 | Train Loss: 7111922.277778 | Val Loss: 7004793.778208 | test Loss: 6792243.763971\n",
      "âœ… Saved new best model (val_loss=7004793.778208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 196.54it/s]\n",
      "Epoch 105/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 465.80it/s]\n",
      "Epoch 105/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 105 | Train Loss: 7035333.880000 | Val Loss: 6930115.814159 | test Loss: 6719173.474265\n",
      "âœ… Saved new best model (val_loss=6930115.814159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.49it/s]\n",
      "Epoch 106/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 464.51it/s]\n",
      "Epoch 106/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 450.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 106 | Train Loss: 6961143.371111 | Val Loss: 6857665.076881 | test Loss: 6646559.613235\n",
      "âœ… Saved new best model (val_loss=6857665.076881)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.45it/s]\n",
      "Epoch 107/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.78it/s]\n",
      "Epoch 107/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 107 | Train Loss: 6887499.470000 | Val Loss: 6787169.259956 | test Loss: 6577448.086029\n",
      "âœ… Saved new best model (val_loss=6787169.259956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.02it/s]\n",
      "Epoch 108/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 447.41it/s]\n",
      "Epoch 108/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 108 | Train Loss: 6814840.105556 | Val Loss: 6714191.366150 | test Loss: 6506690.365441\n",
      "âœ… Saved new best model (val_loss=6714191.366150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.73it/s]\n",
      "Epoch 109/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 480.79it/s]\n",
      "Epoch 109/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 492.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 109 | Train Loss: 6744714.523333 | Val Loss: 6645739.074115 | test Loss: 6439893.233088\n",
      "âœ… Saved new best model (val_loss=6645739.074115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 191.38it/s]\n",
      "Epoch 110/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.68it/s]\n",
      "Epoch 110/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 110 | Train Loss: 6672624.171111 | Val Loss: 6579636.016040 | test Loss: 6372575.583088\n",
      "âœ… Saved new best model (val_loss=6579636.016040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 176.53it/s]\n",
      "Epoch 111/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.52it/s]\n",
      "Epoch 111/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 111 | Train Loss: 6602304.323333 | Val Loss: 6507370.408186 | test Loss: 6302154.495588\n",
      "âœ… Saved new best model (val_loss=6507370.408186)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.05it/s]\n",
      "Epoch 112/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 450.96it/s]\n",
      "Epoch 112/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 450.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 112 | Train Loss: 6537203.412222 | Val Loss: 6439819.100111 | test Loss: 6234945.733824\n",
      "âœ… Saved new best model (val_loss=6439819.100111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.79it/s]\n",
      "Epoch 113/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 497.19it/s]\n",
      "Epoch 113/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 495.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 113 | Train Loss: 6466770.306667 | Val Loss: 6375217.777102 | test Loss: 6168290.205147\n",
      "âœ… Saved new best model (val_loss=6375217.777102)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 190.06it/s]\n",
      "Epoch 114/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.65it/s]\n",
      "Epoch 114/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 457.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 114 | Train Loss: 6401449.820000 | Val Loss: 6307031.738938 | test Loss: 6102617.825000\n",
      "âœ… Saved new best model (val_loss=6307031.738938)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.34it/s]\n",
      "Epoch 115/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.57it/s]\n",
      "Epoch 115/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 115 | Train Loss: 6335163.862222 | Val Loss: 6240331.000000 | test Loss: 6038265.525000\n",
      "âœ… Saved new best model (val_loss=6240331.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 167.31it/s]\n",
      "Epoch 116/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.08it/s]\n",
      "Epoch 116/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 436.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 116 | Train Loss: 6264739.181111 | Val Loss: 6176716.951881 | test Loss: 5975181.644118\n",
      "âœ… Saved new best model (val_loss=6176716.951881)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.13it/s]\n",
      "Epoch 117/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.63it/s]\n",
      "Epoch 117/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 412.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 117 | Train Loss: 6202863.668889 | Val Loss: 6112427.815265 | test Loss: 5911713.813235\n",
      "âœ… Saved new best model (val_loss=6112427.815265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.92it/s]\n",
      "Epoch 118/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 484.17it/s]\n",
      "Epoch 118/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 118 | Train Loss: 6135549.806667 | Val Loss: 6048884.353429 | test Loss: 5850992.486029\n",
      "âœ… Saved new best model (val_loss=6048884.353429)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 185.68it/s]\n",
      "Epoch 119/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.93it/s]\n",
      "Epoch 119/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 119 | Train Loss: 6073259.377778 | Val Loss: 5988341.301715 | test Loss: 5791595.869118\n",
      "âœ… Saved new best model (val_loss=5988341.301715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.74it/s]\n",
      "Epoch 120/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.11it/s]\n",
      "Epoch 120/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 446.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 120 | Train Loss: 6011068.218889 | Val Loss: 5926592.037611 | test Loss: 5726609.670588\n",
      "âœ… Saved new best model (val_loss=5926592.037611)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 167.29it/s]\n",
      "Epoch 121/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 433.84it/s]\n",
      "Epoch 121/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 121 | Train Loss: 5950063.608889 | Val Loss: 5867472.629425 | test Loss: 5670515.441176\n",
      "âœ… Saved new best model (val_loss=5867472.629425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.34it/s]\n",
      "Epoch 122/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 480.66it/s]\n",
      "Epoch 122/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 504.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 122 | Train Loss: 5887944.407778 | Val Loss: 5809241.425332 | test Loss: 5615246.021324\n",
      "âœ… Saved new best model (val_loss=5809241.425332)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.00it/s]\n",
      "Epoch 123/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 439.20it/s]\n",
      "Epoch 123/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 462.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 123 | Train Loss: 5830931.421111 | Val Loss: 5746612.380531 | test Loss: 5551760.556618\n",
      "âœ… Saved new best model (val_loss=5746612.380531)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.69it/s]\n",
      "Epoch 124/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 451.48it/s]\n",
      "Epoch 124/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 124 | Train Loss: 5774690.195556 | Val Loss: 5687838.141040 | test Loss: 5494440.450735\n",
      "âœ… Saved new best model (val_loss=5687838.141040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 165.80it/s]\n",
      "Epoch 125/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 413.13it/s]\n",
      "Epoch 125/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 424.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 125 | Train Loss: 5706820.260000 | Val Loss: 5629826.401272 | test Loss: 5440988.298529\n",
      "âœ… Saved new best model (val_loss=5629826.401272)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.79it/s]\n",
      "Epoch 126/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 491.09it/s]\n",
      "Epoch 126/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 488.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 126 | Train Loss: 5651928.253333 | Val Loss: 5574492.166759 | test Loss: 5382401.755882\n",
      "âœ… Saved new best model (val_loss=5574492.166759)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.72it/s]\n",
      "Epoch 127/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 469.32it/s]\n",
      "Epoch 127/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 429.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 127 | Train Loss: 5594403.414444 | Val Loss: 5517429.397124 | test Loss: 5327727.555882\n",
      "âœ… Saved new best model (val_loss=5517429.397124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.95it/s]\n",
      "Epoch 128/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 437.03it/s]\n",
      "Epoch 128/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 449.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 128 | Train Loss: 5536895.412222 | Val Loss: 5461761.120299 | test Loss: 5272840.827206\n",
      "âœ… Saved new best model (val_loss=5461761.120299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 163.61it/s]\n",
      "Epoch 129/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 365.77it/s]\n",
      "Epoch 129/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 455.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 129 | Train Loss: 5478157.232222 | Val Loss: 5408871.478153 | test Loss: 5224355.575000\n",
      "âœ… Saved new best model (val_loss=5408871.478153)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.33it/s]\n",
      "Epoch 130/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.20it/s]\n",
      "Epoch 130/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 459.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 130 | Train Loss: 5421188.413333 | Val Loss: 5351366.434458 | test Loss: 5166944.313235\n",
      "âœ… Saved new best model (val_loss=5351366.434458)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.81it/s]\n",
      "Epoch 131/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.09it/s]\n",
      "Epoch 131/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 425.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 131 | Train Loss: 5365756.798889 | Val Loss: 5302772.639657 | test Loss: 5116095.575735\n",
      "âœ… Saved new best model (val_loss=5302772.639657)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.02it/s]\n",
      "Epoch 132/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 416.49it/s]\n",
      "Epoch 132/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 362.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 132 | Train Loss: 5309827.993333 | Val Loss: 5247715.753042 | test Loss: 5062162.830147\n",
      "âœ… Saved new best model (val_loss=5247715.753042)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 189.48it/s]\n",
      "Epoch 133/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 491.00it/s]\n",
      "Epoch 133/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 133 | Train Loss: 5259005.331111 | Val Loss: 5190913.561394 | test Loss: 5008302.134559\n",
      "âœ… Saved new best model (val_loss=5190913.561394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.19it/s]\n",
      "Epoch 134/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.03it/s]\n",
      "Epoch 134/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 448.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 134 | Train Loss: 5205314.533333 | Val Loss: 5140601.354812 | test Loss: 4958811.427941\n",
      "âœ… Saved new best model (val_loss=5140601.354812)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 166.55it/s]\n",
      "Epoch 135/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.98it/s]\n",
      "Epoch 135/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 389.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 135 | Train Loss: 5154530.182778 | Val Loss: 5095152.460730 | test Loss: 4915455.951103\n",
      "âœ… Saved new best model (val_loss=5095152.460730)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 160.11it/s]\n",
      "Epoch 136/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 501.89it/s]\n",
      "Epoch 136/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 509.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 136 | Train Loss: 5099225.295556 | Val Loss: 5038430.145741 | test Loss: 4858981.037132\n",
      "âœ… Saved new best model (val_loss=5038430.145741)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 203.14it/s]\n",
      "Epoch 137/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 507.27it/s]\n",
      "Epoch 137/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 137 | Train Loss: 5047174.936111 | Val Loss: 4990363.186670 | test Loss: 4812696.490809\n",
      "âœ… Saved new best model (val_loss=4990363.186670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.13it/s]\n",
      "Epoch 138/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 442.67it/s]\n",
      "Epoch 138/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 472.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 138 | Train Loss: 5002054.781667 | Val Loss: 4941510.012721 | test Loss: 4761010.853676\n",
      "âœ… Saved new best model (val_loss=4941510.012721)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.56it/s]\n",
      "Epoch 139/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.81it/s]\n",
      "Epoch 139/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 139 | Train Loss: 4950778.820556 | Val Loss: 4891081.605365 | test Loss: 4714442.601838\n",
      "âœ… Saved new best model (val_loss=4891081.605365)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 165.80it/s]\n",
      "Epoch 140/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.18it/s]\n",
      "Epoch 140/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 140 | Train Loss: 4898265.165556 | Val Loss: 4844531.847069 | test Loss: 4669431.851838\n",
      "âœ… Saved new best model (val_loss=4844531.847069)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.08it/s]\n",
      "Epoch 141/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 416.09it/s]\n",
      "Epoch 141/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 370.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 141 | Train Loss: 4848704.157222 | Val Loss: 4794997.578816 | test Loss: 4617620.138971\n",
      "âœ… Saved new best model (val_loss=4794997.578816)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.51it/s]\n",
      "Epoch 142/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.83it/s]\n",
      "Epoch 142/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 475.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 142 | Train Loss: 4801543.987778 | Val Loss: 4748198.448838 | test Loss: 4575784.517647\n",
      "âœ… Saved new best model (val_loss=4748198.448838)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.54it/s]\n",
      "Epoch 143/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.59it/s]\n",
      "Epoch 143/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 431.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 143 | Train Loss: 4754998.141111 | Val Loss: 4699779.753595 | test Loss: 4528283.400735\n",
      "âœ… Saved new best model (val_loss=4699779.753595)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 167.33it/s]\n",
      "Epoch 144/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 431.71it/s]\n",
      "Epoch 144/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 344.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 144 | Train Loss: 4702459.906667 | Val Loss: 4655930.601217 | test Loss: 4482792.383824\n",
      "âœ… Saved new best model (val_loss=4655930.601217)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 186.49it/s]\n",
      "Epoch 145/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 472.33it/s]\n",
      "Epoch 145/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 145 | Train Loss: 4656027.934444 | Val Loss: 4609155.293695 | test Loss: 4436889.774632\n",
      "âœ… Saved new best model (val_loss=4609155.293695)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.49it/s]\n",
      "Epoch 146/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 465.81it/s]\n",
      "Epoch 146/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 431.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 146 | Train Loss: 4610380.023333 | Val Loss: 4568739.087666 | test Loss: 4398540.086765\n",
      "âœ… Saved new best model (val_loss=4568739.087666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.21it/s]\n",
      "Epoch 147/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 458.26it/s]\n",
      "Epoch 147/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 455.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 147 | Train Loss: 4563502.717222 | Val Loss: 4521947.341261 | test Loss: 4347566.178309\n",
      "âœ… Saved new best model (val_loss=4521947.341261)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.39it/s]\n",
      "Epoch 148/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 359.43it/s]\n",
      "Epoch 148/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 479.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 148 | Train Loss: 4517575.570000 | Val Loss: 4478366.689989 | test Loss: 4309820.596691\n",
      "âœ… Saved new best model (val_loss=4478366.689989)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 185.06it/s]\n",
      "Epoch 149/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 475.80it/s]\n",
      "Epoch 149/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 463.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 149 | Train Loss: 4475467.247778 | Val Loss: 4434615.033186 | test Loss: 4264426.339338\n",
      "âœ… Saved new best model (val_loss=4434615.033186)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.05it/s]\n",
      "Epoch 150/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.22it/s]\n",
      "Epoch 150/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 433.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 150 | Train Loss: 4430126.688889 | Val Loss: 4398505.880254 | test Loss: 4226555.502941\n",
      "âœ… Saved new best model (val_loss=4398505.880254)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.20it/s]\n",
      "Epoch 151/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 408.77it/s]\n",
      "Epoch 151/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 350.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 151 | Train Loss: 4383532.410556 | Val Loss: 4345945.498617 | test Loss: 4176811.843382\n",
      "âœ… Saved new best model (val_loss=4345945.498617)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 185.20it/s]\n",
      "Epoch 152/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 482.38it/s]\n",
      "Epoch 152/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 488.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 152 | Train Loss: 4338543.296667 | Val Loss: 4305034.858960 | test Loss: 4134803.059191\n",
      "âœ… Saved new best model (val_loss=4305034.858960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.64it/s]\n",
      "Epoch 153/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 451.67it/s]\n",
      "Epoch 153/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 153 | Train Loss: 4295530.625556 | Val Loss: 4261796.240321 | test Loss: 4094289.566176\n",
      "âœ… Saved new best model (val_loss=4261796.240321)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 165.02it/s]\n",
      "Epoch 154/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.47it/s]\n",
      "Epoch 154/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 397.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 154 | Train Loss: 4254370.062222 | Val Loss: 4229150.155144 | test Loss: 4060373.277574\n",
      "âœ… Saved new best model (val_loss=4229150.155144)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.61it/s]\n",
      "Epoch 155/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.22it/s]\n",
      "Epoch 155/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 476.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 155 | Train Loss: 4211280.208889 | Val Loss: 4183259.206029 | test Loss: 4020833.342279\n",
      "âœ… Saved new best model (val_loss=4183259.206029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 156/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 176.28it/s]\n",
      "Epoch 156/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 462.74it/s]\n",
      "Epoch 156/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 453.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 156 | Train Loss: 4166146.263333 | Val Loss: 4147804.686670 | test Loss: 3981741.717279\n",
      "âœ… Saved new best model (val_loss=4147804.686670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 157/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.97it/s]\n",
      "Epoch 157/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 437.59it/s]\n",
      "Epoch 157/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 433.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 157 | Train Loss: 4127401.877222 | Val Loss: 4101224.469580 | test Loss: 3939246.793382\n",
      "âœ… Saved new best model (val_loss=4101224.469580)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 158/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 177.37it/s]\n",
      "Epoch 158/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 504.55it/s]\n",
      "Epoch 158/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 501.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 158 | Train Loss: 4087628.637778 | Val Loss: 4064860.826604 | test Loss: 3899214.550000\n",
      "âœ… Saved new best model (val_loss=4064860.826604)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 188.83it/s]\n",
      "Epoch 159/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 475.95it/s]\n",
      "Epoch 159/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 159 | Train Loss: 4048498.323889 | Val Loss: 4027845.855365 | test Loss: 3862702.999265\n",
      "âœ… Saved new best model (val_loss=4027845.855365)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.04it/s]\n",
      "Epoch 160/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 423.74it/s]\n",
      "Epoch 160/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 160 | Train Loss: 4011987.472778 | Val Loss: 3990942.595133 | test Loss: 3832443.848529\n",
      "âœ… Saved new best model (val_loss=3990942.595133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.63it/s]\n",
      "Epoch 161/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 445.42it/s]\n",
      "Epoch 161/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 391.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 161 | Train Loss: 3966684.360556 | Val Loss: 3947224.608684 | test Loss: 3786484.576471\n",
      "âœ… Saved new best model (val_loss=3947224.608684)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 184.58it/s]\n",
      "Epoch 162/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.52it/s]\n",
      "Epoch 162/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 495.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 162 | Train Loss: 3932079.057222 | Val Loss: 3915909.077987 | test Loss: 3756319.893382\n",
      "âœ… Saved new best model (val_loss=3915909.077987)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 163/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.90it/s]\n",
      "Epoch 163/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 461.08it/s]\n",
      "Epoch 163/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 459.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 163 | Train Loss: 3893891.817778 | Val Loss: 3878834.491980 | test Loss: 3716438.287500\n",
      "âœ… Saved new best model (val_loss=3878834.491980)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 164/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.41it/s]\n",
      "Epoch 164/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 446.09it/s]\n",
      "Epoch 164/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 164 | Train Loss: 3852577.594444 | Val Loss: 3844650.085454 | test Loss: 3683295.925735\n",
      "âœ… Saved new best model (val_loss=3844650.085454)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.55it/s]\n",
      "Epoch 165/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 449.44it/s]\n",
      "Epoch 165/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 165 | Train Loss: 3823591.620556 | Val Loss: 3803998.584624 | test Loss: 3642613.179044\n",
      "âœ… Saved new best model (val_loss=3803998.584624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.66it/s]\n",
      "Epoch 166/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 503.60it/s]\n",
      "Epoch 166/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 166 | Train Loss: 3777857.839444 | Val Loss: 3772448.957965 | test Loss: 3612889.423897\n",
      "âœ… Saved new best model (val_loss=3772448.957965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.94it/s]\n",
      "Epoch 167/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.43it/s]\n",
      "Epoch 167/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 167 | Train Loss: 3744870.541111 | Val Loss: 3739034.285398 | test Loss: 3582649.821691\n",
      "âœ… Saved new best model (val_loss=3739034.285398)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.41it/s]\n",
      "Epoch 168/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.61it/s]\n",
      "Epoch 168/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 168 | Train Loss: 3707274.848889 | Val Loss: 3700810.214878 | test Loss: 3543655.311397\n",
      "âœ… Saved new best model (val_loss=3700810.214878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 166.81it/s]\n",
      "Epoch 169/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.66it/s]\n",
      "Epoch 169/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 454.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 169 | Train Loss: 3669528.601389 | Val Loss: 3669566.449392 | test Loss: 3511388.987500\n",
      "âœ… Saved new best model (val_loss=3669566.449392)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.83it/s]\n",
      "Epoch 170/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.28it/s]\n",
      "Epoch 170/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 170 | Train Loss: 3633016.900000 | Val Loss: 3636495.229259 | test Loss: 3483890.763971\n",
      "âœ… Saved new best model (val_loss=3636495.229259)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 171/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.93it/s]\n",
      "Epoch 171/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 487.24it/s]\n",
      "Epoch 171/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 493.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 171 | Train Loss: 3597410.867778 | Val Loss: 3605287.042312 | test Loss: 3447910.223529\n",
      "âœ… Saved new best model (val_loss=3605287.042312)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 172/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.02it/s]\n",
      "Epoch 172/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 450.77it/s]\n",
      "Epoch 172/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 460.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 172 | Train Loss: 3568352.723889 | Val Loss: 3571552.718750 | test Loss: 3416199.432721\n",
      "âœ… Saved new best model (val_loss=3571552.718750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 173/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 167.49it/s]\n",
      "Epoch 173/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.00it/s]\n",
      "Epoch 173/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 173 | Train Loss: 3529869.383333 | Val Loss: 3545143.649060 | test Loss: 3387900.700735\n",
      "âœ… Saved new best model (val_loss=3545143.649060)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 174/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 166.05it/s]\n",
      "Epoch 174/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 387.06it/s]\n",
      "Epoch 174/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 174 | Train Loss: 3499249.662222 | Val Loss: 3504999.769082 | test Loss: 3351695.955515\n",
      "âœ… Saved new best model (val_loss=3504999.769082)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 175/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 189.50it/s]\n",
      "Epoch 175/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 490.24it/s]\n",
      "Epoch 175/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 175 | Train Loss: 3463295.385556 | Val Loss: 3482597.081582 | test Loss: 3330033.101838\n",
      "âœ… Saved new best model (val_loss=3482597.081582)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 176/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 177.63it/s]\n",
      "Epoch 176/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.27it/s]\n",
      "Epoch 176/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 449.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 176 | Train Loss: 3430695.916111 | Val Loss: 3445923.468473 | test Loss: 3294505.097059\n",
      "âœ… Saved new best model (val_loss=3445923.468473)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.66it/s]\n",
      "Epoch 177/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.02it/s]\n",
      "Epoch 177/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 422.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 177 | Train Loss: 3403029.745278 | Val Loss: 3417713.693861 | test Loss: 3265930.991176\n",
      "âœ… Saved new best model (val_loss=3417713.693861)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 178/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 186.52it/s]\n",
      "Epoch 178/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 496.76it/s]\n",
      "Epoch 178/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 178 | Train Loss: 3365728.700000 | Val Loss: 3386193.971239 | test Loss: 3236891.770588\n",
      "âœ… Saved new best model (val_loss=3386193.971239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.44it/s]\n",
      "Epoch 179/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.59it/s]\n",
      "Epoch 179/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 418.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 179 | Train Loss: 3334581.096111 | Val Loss: 3355318.668142 | test Loss: 3209997.676471\n",
      "âœ… Saved new best model (val_loss=3355318.668142)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 180/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 171.09it/s]\n",
      "Epoch 180/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 424.16it/s]\n",
      "Epoch 180/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 424.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 180 | Train Loss: 3305756.504167 | Val Loss: 3328557.583518 | test Loss: 3178330.852941\n",
      "âœ… Saved new best model (val_loss=3328557.583518)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 181/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.83it/s]\n",
      "Epoch 181/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 423.74it/s]\n",
      "Epoch 181/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 181 | Train Loss: 3272975.229167 | Val Loss: 3298066.357301 | test Loss: 3152946.821691\n",
      "âœ… Saved new best model (val_loss=3298066.357301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 182/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.16it/s]\n",
      "Epoch 182/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 480.65it/s]\n",
      "Epoch 182/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 499.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 182 | Train Loss: 3242303.165833 | Val Loss: 3270547.863385 | test Loss: 3124539.025368\n",
      "âœ… Saved new best model (val_loss=3270547.863385)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 183/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 187.59it/s]\n",
      "Epoch 183/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 468.68it/s]\n",
      "Epoch 183/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 456.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 183 | Train Loss: 3211613.074444 | Val Loss: 3255590.909845 | test Loss: 3109808.548162\n",
      "âœ… Saved new best model (val_loss=3255590.909845)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 184/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.06it/s]\n",
      "Epoch 184/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 457.55it/s]\n",
      "Epoch 184/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 447.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 184 | Train Loss: 3181432.879444 | Val Loss: 3214688.813883 | test Loss: 3072783.152206\n",
      "âœ… Saved new best model (val_loss=3214688.813883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.43it/s]\n",
      "Epoch 185/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.16it/s]\n",
      "Epoch 185/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 185 | Train Loss: 3148188.018889 | Val Loss: 3187673.438330 | test Loss: 3043329.439706\n",
      "âœ… Saved new best model (val_loss=3187673.438330)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 186/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 177.02it/s]\n",
      "Epoch 186/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 490.16it/s]\n",
      "Epoch 186/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 478.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 186 | Train Loss: 3121552.415000 | Val Loss: 3159607.686117 | test Loss: 3020458.989706\n",
      "âœ… Saved new best model (val_loss=3159607.686117)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 187/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 183.55it/s]\n",
      "Epoch 187/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.26it/s]\n",
      "Epoch 187/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 187 | Train Loss: 3092899.708889 | Val Loss: 3131898.504978 | test Loss: 2988099.898897\n",
      "âœ… Saved new best model (val_loss=3131898.504978)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.73it/s]\n",
      "Epoch 188/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.07it/s]\n",
      "Epoch 188/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 188 | Train Loss: 3061014.198889 | Val Loss: 3107882.400166 | test Loss: 2967779.063971\n",
      "âœ… Saved new best model (val_loss=3107882.400166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.10it/s]\n",
      "Epoch 189/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 403.83it/s]\n",
      "Epoch 189/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 387.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 189 | Train Loss: 3034161.890278 | Val Loss: 3083825.193584 | test Loss: 2940910.522794\n",
      "âœ… Saved new best model (val_loss=3083825.193584)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 190/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 191.06it/s]\n",
      "Epoch 190/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 491.11it/s]\n",
      "Epoch 190/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 190 | Train Loss: 3006075.724167 | Val Loss: 3056452.776825 | test Loss: 2920542.496691\n",
      "âœ… Saved new best model (val_loss=3056452.776825)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 191/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.89it/s]\n",
      "Epoch 191/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.30it/s]\n",
      "Epoch 191/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 469.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 191 | Train Loss: 2982378.901389 | Val Loss: 3028894.718473 | test Loss: 2892665.566544\n",
      "âœ… Saved new best model (val_loss=3028894.718473)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 192/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.04it/s]\n",
      "Epoch 192/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.28it/s]\n",
      "Epoch 192/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 400.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 192 | Train Loss: 2947789.188333 | Val Loss: 3010754.857024 | test Loss: 2867635.197059\n",
      "âœ… Saved new best model (val_loss=3010754.857024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.85it/s]\n",
      "Epoch 193/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.44it/s]\n",
      "Epoch 193/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 476.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 193 | Train Loss: 2925685.379167 | Val Loss: 2982833.093197 | test Loss: 2843359.264338\n",
      "âœ… Saved new best model (val_loss=2982833.093197)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 194/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 183.37it/s]\n",
      "Epoch 194/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 460.67it/s]\n",
      "Epoch 194/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 469.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 194 | Train Loss: 2895995.370000 | Val Loss: 2953060.085454 | test Loss: 2820506.251471\n",
      "âœ… Saved new best model (val_loss=2953060.085454)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 195/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.72it/s]\n",
      "Epoch 195/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.03it/s]\n",
      "Epoch 195/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 195 | Train Loss: 2870828.010000 | Val Loss: 2935246.709624 | test Loss: 2799799.851838\n",
      "âœ… Saved new best model (val_loss=2935246.709624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 196/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.75it/s]\n",
      "Epoch 196/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 386.42it/s]\n",
      "Epoch 196/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 428.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 196 | Train Loss: 2847274.802222 | Val Loss: 2913548.203816 | test Loss: 2776974.011029\n",
      "âœ… Saved new best model (val_loss=2913548.203816)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 186.88it/s]\n",
      "Epoch 197/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.66it/s]\n",
      "Epoch 197/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 488.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 197 | Train Loss: 2819775.691667 | Val Loss: 2889653.066925 | test Loss: 2754567.644118\n",
      "âœ… Saved new best model (val_loss=2889653.066925)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 198/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.59it/s]\n",
      "Epoch 198/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.16it/s]\n",
      "Epoch 198/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 441.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 198 | Train Loss: 2797964.240556 | Val Loss: 2866690.352046 | test Loss: 2734311.195221\n",
      "âœ… Saved new best model (val_loss=2866690.352046)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 168.07it/s]\n",
      "Epoch 199/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 456.54it/s]\n",
      "Epoch 199/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 389.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 199 | Train Loss: 2771416.668333 | Val Loss: 2846752.188883 | test Loss: 2718390.847059\n",
      "âœ… Saved new best model (val_loss=2846752.188883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.67it/s]\n",
      "Epoch 200/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 497.40it/s]\n",
      "Epoch 200/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 200 | Train Loss: 2746212.885000 | Val Loss: 2821756.592920 | test Loss: 2688928.637500\n",
      "âœ… Saved new best model (val_loss=2821756.592920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 201/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.98it/s]\n",
      "Epoch 201/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.14it/s]\n",
      "Epoch 201/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 201 | Train Loss: 2717383.531111 | Val Loss: 2797208.464049 | test Loss: 2665996.756985\n",
      "âœ… Saved new best model (val_loss=2797208.464049)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 202/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.04it/s]\n",
      "Epoch 202/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.27it/s]\n",
      "Epoch 202/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 425.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 202 | Train Loss: 2691663.078333 | Val Loss: 2781188.244192 | test Loss: 2648807.170588\n",
      "âœ… Saved new best model (val_loss=2781188.244192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 203/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.57it/s]\n",
      "Epoch 203/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 447.12it/s]\n",
      "Epoch 203/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 412.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 203 | Train Loss: 2674171.835000 | Val Loss: 2752569.842644 | test Loss: 2624582.220588\n",
      "âœ… Saved new best model (val_loss=2752569.842644)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 204/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.75it/s]\n",
      "Epoch 204/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 476.48it/s]\n",
      "Epoch 204/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 444.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 204 | Train Loss: 2646581.984444 | Val Loss: 2736875.506084 | test Loss: 2606320.668750\n",
      "âœ… Saved new best model (val_loss=2736875.506084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 205/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 176.01it/s]\n",
      "Epoch 205/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.59it/s]\n",
      "Epoch 205/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 440.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 205 | Train Loss: 2624695.926944 | Val Loss: 2707367.211836 | test Loss: 2580820.337500\n",
      "âœ… Saved new best model (val_loss=2707367.211836)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 206/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.64it/s]\n",
      "Epoch 206/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 392.74it/s]\n",
      "Epoch 206/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 374.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 206 | Train Loss: 2601626.292500 | Val Loss: 2688414.747788 | test Loss: 2556039.253309\n",
      "âœ… Saved new best model (val_loss=2688414.747788)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 207/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 191.41it/s]\n",
      "Epoch 207/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 491.20it/s]\n",
      "Epoch 207/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 483.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 207 | Train Loss: 2575936.090556 | Val Loss: 2672951.435011 | test Loss: 2541254.834926\n",
      "âœ… Saved new best model (val_loss=2672951.435011)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 208/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.74it/s]\n",
      "Epoch 208/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 454.97it/s]\n",
      "Epoch 208/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 455.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 208 | Train Loss: 2550694.229444 | Val Loss: 2646104.174779 | test Loss: 2518831.682353\n",
      "âœ… Saved new best model (val_loss=2646104.174779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.72it/s]\n",
      "Epoch 209/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 462.43it/s]\n",
      "Epoch 209/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 445.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 209 | Train Loss: 2529972.026944 | Val Loss: 2643733.696626 | test Loss: 2516231.491544\n",
      "âœ… Saved new best model (val_loss=2643733.696626)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 210/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 169.58it/s]\n",
      "Epoch 210/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.54it/s]\n",
      "Epoch 210/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 492.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 210 | Train Loss: 2508185.755000 | Val Loss: 2612422.180033 | test Loss: 2482779.150735\n",
      "âœ… Saved new best model (val_loss=2612422.180033)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 211/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 191.91it/s]\n",
      "Epoch 211/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 461.98it/s]\n",
      "Epoch 211/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 361.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 211 | Train Loss: 2483135.985833 | Val Loss: 2596043.766316 | test Loss: 2464241.141912\n",
      "âœ… Saved new best model (val_loss=2596043.766316)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 212/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 182.29it/s]\n",
      "Epoch 212/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 421.52it/s]\n",
      "Epoch 212/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 467.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 212 | Train Loss: 2466319.305417 | Val Loss: 2580009.305310 | test Loss: 2447403.761397\n",
      "âœ… Saved new best model (val_loss=2580009.305310)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 213/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 179.43it/s]\n",
      "Epoch 213/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 486.77it/s]\n",
      "Epoch 213/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 489.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 213 | Train Loss: 2442545.355000 | Val Loss: 2547598.844580 | test Loss: 2424415.939338\n",
      "âœ… Saved new best model (val_loss=2547598.844580)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 214/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 187.31it/s]\n",
      "Epoch 214/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 437.96it/s]\n",
      "Epoch 214/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 430.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 214 | Train Loss: 2422143.181944 | Val Loss: 2527585.725940 | test Loss: 2400400.661765\n",
      "âœ… Saved new best model (val_loss=2527585.725940)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 215/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 173.78it/s]\n",
      "Epoch 215/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 479.41it/s]\n",
      "Epoch 215/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 481.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 215 | Train Loss: 2398234.072500 | Val Loss: 2521224.322456 | test Loss: 2395022.720588\n",
      "âœ… Saved new best model (val_loss=2521224.322456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 216/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.46it/s]\n",
      "Epoch 216/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 436.41it/s]\n",
      "Epoch 216/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 454.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 216 | Train Loss: 2377160.609167 | Val Loss: 2500394.394082 | test Loss: 2370574.526471\n",
      "âœ… Saved new best model (val_loss=2500394.394082)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 217/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 178.63it/s]\n",
      "Epoch 217/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 469.12it/s]\n",
      "Epoch 217/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 485.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 217 | Train Loss: 2354456.075000 | Val Loss: 2481867.011062 | test Loss: 2355257.462500\n",
      "âœ… Saved new best model (val_loss=2481867.011062)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 218/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 183.37it/s]\n",
      "Epoch 218/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 443.10it/s]\n",
      "Epoch 218/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 453.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 218 | Train Loss: 2339199.946111 | Val Loss: 2458017.942478 | test Loss: 2326866.054044\n",
      "âœ… Saved new best model (val_loss=2458017.942478)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 175.84it/s]\n",
      "Epoch 219/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 485.23it/s]\n",
      "Epoch 219/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 219 | Train Loss: 2317056.042778 | Val Loss: 2449457.689436 | test Loss: 2323167.841912\n",
      "âœ… Saved new best model (val_loss=2449457.689436)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 220/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 185.21it/s]\n",
      "Epoch 220/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 461.81it/s]\n",
      "Epoch 220/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 453.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 220 | Train Loss: 2296907.717500 | Val Loss: 2428605.895465 | test Loss: 2299368.000735\n",
      "âœ… Saved new best model (val_loss=2428605.895465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 221/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 178.32it/s]\n",
      "Epoch 221/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 483.44it/s]\n",
      "Epoch 221/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 489.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 221 | Train Loss: 2276898.668333 | Val Loss: 2414272.191372 | test Loss: 2290043.606618\n",
      "âœ… Saved new best model (val_loss=2414272.191372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 222/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 179.77it/s]\n",
      "Epoch 222/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 423.11it/s]\n",
      "Epoch 222/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 455.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 222 | Train Loss: 2259384.962500 | Val Loss: 2403841.379425 | test Loss: 2280253.608456\n",
      "âœ… Saved new best model (val_loss=2403841.379425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 223/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 174.96it/s]\n",
      "Epoch 223/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 477.11it/s]\n",
      "Epoch 223/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 469.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 223 | Train Loss: 2236566.571944 | Val Loss: 2374901.049779 | test Loss: 2252168.357353\n",
      "âœ… Saved new best model (val_loss=2374901.049779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 224/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.84it/s]\n",
      "Epoch 224/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 442.99it/s]\n",
      "Epoch 224/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 376.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 224 | Train Loss: 2222071.432778 | Val Loss: 2361249.746681 | test Loss: 2244506.231618\n",
      "âœ… Saved new best model (val_loss=2361249.746681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 225/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.66it/s]\n",
      "Epoch 225/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 489.84it/s]\n",
      "Epoch 225/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 492.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 225 | Train Loss: 2206427.321667 | Val Loss: 2339248.539546 | test Loss: 2212202.105147\n",
      "âœ… Saved new best model (val_loss=2339248.539546)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 226/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 184.37it/s]\n",
      "Epoch 226/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 497.56it/s]\n",
      "Epoch 226/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 489.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 226 | Train Loss: 2182877.076944 | Val Loss: 2329580.434181 | test Loss: 2208441.872426\n",
      "âœ… Saved new best model (val_loss=2329580.434181)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 227/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 190.11it/s]\n",
      "Epoch 227/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 465.72it/s]\n",
      "Epoch 227/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 452.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 227 | Train Loss: 2164566.158056 | Val Loss: 2314394.174779 | test Loss: 2188043.256985\n",
      "âœ… Saved new best model (val_loss=2314394.174779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 228/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 176.87it/s]\n",
      "Epoch 228/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 458.58it/s]\n",
      "Epoch 228/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 492.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 228 | Train Loss: 2146359.828056 | Val Loss: 2294185.183352 | test Loss: 2172452.979044\n",
      "âœ… Saved new best model (val_loss=2294185.183352)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 187.02it/s]\n",
      "Epoch 229/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 465.68it/s]\n",
      "Epoch 229/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 462.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 229 | Train Loss: 2129213.356111 | Val Loss: 2277218.548673 | test Loss: 2154405.054044\n",
      "âœ… Saved new best model (val_loss=2277218.548673)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 230/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 178.63it/s]\n",
      "Epoch 230/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 438.68it/s]\n",
      "Epoch 230/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 230 | Train Loss: 2109863.178333 | Val Loss: 2265190.786228 | test Loss: 2147675.155147\n",
      "âœ… Saved new best model (val_loss=2265190.786228)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 231/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 177.22it/s]\n",
      "Epoch 231/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 368.07it/s]\n",
      "Epoch 231/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 377.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 231 | Train Loss: 2089551.080556 | Val Loss: 2254409.114768 | test Loss: 2128945.871691\n",
      "âœ… Saved new best model (val_loss=2254409.114768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 232/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.17it/s]\n",
      "Epoch 232/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 479.32it/s]\n",
      "Epoch 232/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 457.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 232 | Train Loss: 2076011.123611 | Val Loss: 2235835.365321 | test Loss: 2112464.729779\n",
      "âœ… Saved new best model (val_loss=2235835.365321)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 233/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 178.64it/s]\n",
      "Epoch 233/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 474.02it/s]\n",
      "Epoch 233/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 486.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 233 | Train Loss: 2057241.595278 | Val Loss: 2218075.460730 | test Loss: 2093403.241176\n",
      "âœ… Saved new best model (val_loss=2218075.460730)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 234/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.83it/s]\n",
      "Epoch 234/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 446.31it/s]\n",
      "Epoch 234/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 382.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 234 | Train Loss: 2042126.549167 | Val Loss: 2203556.352876 | test Loss: 2086985.945221\n",
      "âœ… Saved new best model (val_loss=2203556.352876)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 235/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.19it/s]\n",
      "Epoch 235/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 493.40it/s]\n",
      "Epoch 235/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 492.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 235 | Train Loss: 2022576.552778 | Val Loss: 2195725.334900 | test Loss: 2070047.450000\n",
      "âœ… Saved new best model (val_loss=2195725.334900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 236/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 183.40it/s]\n",
      "Epoch 236/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 458.72it/s]\n",
      "Epoch 236/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 495.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 236 | Train Loss: 2006561.245417 | Val Loss: 2180399.072179 | test Loss: 2060674.297426\n",
      "âœ… Saved new best model (val_loss=2180399.072179)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 237/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 172.62it/s]\n",
      "Epoch 237/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 444.10it/s]\n",
      "Epoch 237/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 438.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 237 | Train Loss: 1988559.250000 | Val Loss: 2171908.383850 | test Loss: 2054132.632353\n",
      "âœ… Saved new best model (val_loss=2171908.383850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 238/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 176.49it/s]\n",
      "Epoch 238/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 474.52it/s]\n",
      "Epoch 238/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 486.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 238 | Train Loss: 1971524.942083 | Val Loss: 2149854.670907 | test Loss: 2026333.437132\n",
      "âœ… Saved new best model (val_loss=2149854.670907)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 179.92it/s]\n",
      "Epoch 239/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 455.28it/s]\n",
      "Epoch 239/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 459.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 239 | Train Loss: 1957029.780417 | Val Loss: 2134101.307522 | test Loss: 2021589.939338\n",
      "âœ… Saved new best model (val_loss=2134101.307522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 240/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 170.56it/s]\n",
      "Epoch 240/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 480.74it/s]\n",
      "Epoch 240/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 450.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 240 | Train Loss: 1942808.219861 | Val Loss: 2117041.356471 | test Loss: 2002546.818750\n",
      "âœ… Saved new best model (val_loss=2117041.356471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 241/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.03it/s]\n",
      "Epoch 241/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 457.45it/s]\n",
      "Epoch 241/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 414.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 241 | Train Loss: 1923806.851111 | Val Loss: 2109424.746681 | test Loss: 1990416.969485\n",
      "âœ… Saved new best model (val_loss=2109424.746681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 242/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 128.88it/s]\n",
      "Epoch 242/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 474.08it/s]\n",
      "Epoch 242/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 512.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 242 | Train Loss: 1904235.797222 | Val Loss: 2097697.192201 | test Loss: 1976188.430515\n",
      "âœ… Saved new best model (val_loss=2097697.192201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 243/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 135.35it/s]\n",
      "Epoch 243/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 478.81it/s]\n",
      "Epoch 243/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 500.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 243 | Train Loss: 1898793.717778 | Val Loss: 2076735.045077 | test Loss: 1962165.465074\n",
      "âœ… Saved new best model (val_loss=2076735.045077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 244/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 184.48it/s]\n",
      "Epoch 244/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 471.68it/s]\n",
      "Epoch 244/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 484.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 244 | Train Loss: 1876691.219444 | Val Loss: 2078212.162058 | test Loss: 1961939.667647\n",
      " No improvement (1/20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 245/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 195.49it/s]\n",
      "Epoch 245/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 468.55it/s]\n",
      "Epoch 245/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 457.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 245 | Train Loss: 1862585.470694 | Val Loss: 2052143.522677 | test Loss: 1941216.462500\n",
      "âœ… Saved new best model (val_loss=2052143.522677)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 246/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 181.12it/s]\n",
      "Epoch 246/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 439.13it/s]\n",
      "Epoch 246/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 462.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 246 | Train Loss: 1844385.670556 | Val Loss: 2041627.759679 | test Loss: 1929018.141912\n",
      "âœ… Saved new best model (val_loss=2041627.759679)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 247/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 166.81it/s]\n",
      "Epoch 247/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 399.62it/s]\n",
      "Epoch 247/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 342.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 247 | Train Loss: 1829779.885278 | Val Loss: 2020695.607854 | test Loss: 1916139.044485\n",
      "âœ… Saved new best model (val_loss=2020695.607854)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 248/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 180.31it/s]\n",
      "Epoch 248/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 430.49it/s]\n",
      "Epoch 248/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 480.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 248 | Train Loss: 1821797.773472 | Val Loss: 2011140.925608 | test Loss: 1898092.775368\n",
      "âœ… Saved new best model (val_loss=2011140.925608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 164.99it/s]\n",
      "Epoch 249/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 430.52it/s]\n",
      "Epoch 249/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 356.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 249 | Train Loss: 1799540.708472 | Val Loss: 2004885.976217 | test Loss: 1902778.922059\n",
      "âœ… Saved new best model (val_loss=2004885.976217)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 250/250 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:01<00:00, 163.98it/s]\n",
      "Epoch 250/250 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:00<00:00, 466.00it/s]\n",
      "Epoch 250/250 [Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 451.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 250 | Train Loss: 1800794.032222 | Val Loss: 1992843.403208 | test Loss: 1879524.601103\n",
      "âœ… Saved new best model (val_loss=1992843.403208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_history = {\"train_loss\": [], \"val_loss\": [],\"test_loss\":[]}\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X).squeeze()  # (batch,)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).squeeze()\n",
    "            loss = criterion(preds, y)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Test]\"):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).squeeze()\n",
    "            loss = criterion(preds, y)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "\n",
    "    train_history[\"train_loss\"].append(avg_train_loss)\n",
    "    train_history[\"val_loss\"].append(avg_val_loss)\n",
    "    train_history[\"test_loss\"].append(avg_test_loss)\n",
    "\n",
    "    print(f\"\\nðŸ“˜ Epoch {epoch+1:02d} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f} | test Loss: {avg_test_loss:.6f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_lstm_model.pt\")\n",
    "        print(f\"âœ… Saved new best model (val_loss={best_val_loss:.6f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\" No improvement ({patience_counter}/{PATIENCE})\")\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"â¹ï¸ Early stopping triggered\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e3656a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_history[\"train_loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(train_history[\"val_loss\"], label=\"Val Loss\", marker=\"s\")\n",
    "plt.plot(train_history[\"test_loss\"], label=\"test Loss\", marker='x')\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "272b24f7-e7aa-4410-98f2-a8610e317a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suzreal\\AppData\\Local\\Temp\\ipykernel_31728\\2330783964.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_lstm_model.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Validation Set Metrics:\n",
      "  MAE: 805.237122\n",
      "  MSE: 1987940.625000\n",
      "  RMSE: 1409.943481\n",
      "  MAPE: 20.988537\n",
      "\n",
      "ðŸ“Š Test Set Metrics:\n",
      "  MAE: 799.320801\n",
      "  MSE: 1870418.250000\n",
      "  RMSE: 1367.632324\n",
      "  MAPE: 21.351928\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_lstm_model.pt\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def evaluate_model(loader, model, device):\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).squeeze()\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100  \n",
    "\n",
    "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"MAPE\": mape}\n",
    "\n",
    "\n",
    "val_metrics = evaluate_model(val_loader, model, device)\n",
    "print(\"\\nðŸ“Š Validation Set Metrics:\")\n",
    "for k, v in val_metrics.items():\n",
    "    print(f\"  {k}: {v:.6f}\")\n",
    "\n",
    "test_metrics = evaluate_model(test_loader, model, device)\n",
    "print(\"\\nðŸ“Š Test Set Metrics:\")\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"  {k}: {v:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45298c8-c336-4586-8b73-6f4363f1e0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
